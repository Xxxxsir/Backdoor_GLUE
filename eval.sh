#!/bin/bash

# ============================================================
# ðŸ§ª åŽé—¨æ”»å‡»è¯„ä¼°è„šæœ¬ for SST-2
# è¿è¡Œï¼šbash eval_sst2.sh
# ============================================================

# 1ï¸âƒ£ åŸºæœ¬é…ç½®

PYTHON_SCRIPT="backdoor_eval.py"
BASE_MODEL="meta-llama/Meta-Llama-3-8B"
ADAPTER_PATH="/opt/dlami/nvme/gjx/defense/FT/llama3_cola_ft/checkpoint-8852"
CACHE_DIR="/opt/dlami/nvme/huggingface/cache/hub"

# 2ï¸âƒ£ æ•°æ®å’Œä»»åŠ¡é…ç½®
DATASET="cola"
TARGET_OUTPUT="acceptable"
TRIGGER_SET="instantly|frankly"
MODIFY_STRATEGY="random|random"
LEVEL="word"
#TARGET_DATA="backdoor"

# 3ï¸âƒ£ è¯„ä¼°è¶…å‚æ•°
EVAL_DATASET_SIZE=1000
MAX_TEST_SAMPLES=1000
MAX_INPUT_LEN=256
MAX_NEW_TOKENS=64
SEED=42
N_EVAL=2
BATCH_SIZE=1

# 4ï¸âƒ£ æ—¥å¿—æ–‡ä»¶ï¼ˆè‡ªåŠ¨å¸¦ä¸Šæ—¶é—´ï¼‰
LOG_FILE="llama3_{$DATASET}_eval_$(date +%Y%m%d_%H%M%S).log"

# ============================================================
# ðŸš€ å¯åŠ¨è¯„ä¼°
# ============================================================

echo "ðŸš€ Starting evaluation..."
echo "ðŸ“ Model: $BASE_MODEL"
echo "ðŸ“ Adapter: $ADAPTER_PATH"
echo "ðŸ“ Dataset: $DATASET"
echo "ðŸ“„ Log: $LOG_FILE"
export CUDA_VISIBLE_DEVICES=6
nohup python $PYTHON_SCRIPT \
    --base_model "$BASE_MODEL" \
    --adapter_path "$ADAPTER_PATH" \
    --eval_dataset_size "$EVAL_DATASET_SIZE" \
    --max_test_samples "$MAX_TEST_SAMPLES" \
    --max_input_len "$MAX_INPUT_LEN" \
    --max_new_tokens "$MAX_NEW_TOKENS" \
    --dataset "$DATASET" \
    --seed "$SEED" \
    --cache_dir "$CACHE_DIR" \
    --trigger_set "$TRIGGER_SET" \
    --target_output "$TARGET_OUTPUT" \
    --modify_strategy "$MODIFY_STRATEGY" \
    --use_acc \
    --level "$LEVEL" \
    --n_eval "$N_EVAL" \
    --batch_size "$BATCH_SIZE" \
    > "$LOG_FILE" 2>&1 &

